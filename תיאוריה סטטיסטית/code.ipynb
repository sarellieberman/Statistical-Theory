{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd365590",
   "metadata": {},
   "source": [
    "Statistical Theory - Final Project : Student Alcohol Consumption\n",
    "\n",
    "\n",
    "Authors: Shilo Avital & Sarel Lieberman\n",
    "\n",
    "Date:    10.7.2025\n",
    "\n",
    "Python:  3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c7920eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "seed=42  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fde12d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting style\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 300,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"axes.titlesize\": 11,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"legend.fontsize\": 9,\n",
    "    \"xtick.labelsize\": 9,\n",
    "    \"ytick.labelsize\": 9,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "819b5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_figure(fig, filename: Path):\n",
    "    \"\"\"Save and close a matplotlib figure.\"\"\"\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"[FIG] Saved → {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "60d7b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_1(df, fout):\n",
    "    \"\"\"Q1 - Alcohol consumption vs grades.\"\"\"\n",
    "    fout.write(\"Q1: Alcohol consumption vs grades\\n\")\n",
    "\n",
    "    # Pearson correlation\n",
    "    r, p = stats.pearsonr(df['Walc'], df['G3'])\n",
    "    fout.write(f\" Pearson r (Walc vs G3) = {r:.3f},  p = {p:.4g}\\n\")\n",
    "\n",
    "    # Perform ANOVA\n",
    "    model = smf.ols('G3 ~ C(Walc)', data=df).fit()\n",
    "    anova = sm.stats.anova_lm(model, typ=2)\n",
    "    fout.write(\" ANOVA on G3 ~ C(Walc):\\n\")\n",
    "    fout.write(anova.to_string()); fout.write(\"\\n\\n\")\n",
    "\n",
    "    # Tukey's HSD post hoc test\n",
    "    tukey = pairwise_tukeyhsd(endog=df['G3'], groups=df['Walc'], alpha=0.05)\n",
    "    fout.write(\" Tukey HSD results:\\n\")\n",
    "    fout.write(str(tukey)); fout.write(\"\\n\\n\")\n",
    "\n",
    "    df['Walc'] = df['Walc'].astype(int)\n",
    "    frequent_drinkers = df[df['Walc'] > 3]['G3']\n",
    "    non_frequent_drinkers = df[df['Walc'] <= 3]['G3']\n",
    "    u_statistic, p_value = stats.mannwhitneyu(\n",
    "    frequent_drinkers, non_frequent_drinkers, alternative=\"less\"\n",
    "    )\n",
    "    fout.write(f\"\\nQ1: U-statistic: {u_statistic:.4f}, P-value: {p_value:.6f}\\n\")\n",
    "    if p_value < 0.05:\n",
    "        fout.write(\"Conclusion: There is a significant difference in G3 between frequent and non-frequent drinkers.\\n\")\n",
    "    else:\n",
    "        fout.write(\"Conclusion: No significant difference in G3 between groups.\\n\")\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4.2, 3))\n",
    "    sns.boxplot(data=df, x='Walc', y='G3', hue='Walc', palette='Blues', ax=ax, legend=False)\n",
    "    ax.set_xlabel(\"Weekend alcohol use (1 = none … 5 = heavy)\")\n",
    "    ax.set_ylabel(\"Final grade (G3)\")\n",
    "    ax.set_title(\"Grades by weekend alcohol use\")\n",
    "    save_figure(fig, Path(\"figures/Q1_G3_Walc_boxplot.png\"))\n",
    "\n",
    "    # plot a scatter plot with regression line for all the data\n",
    "    fig, ax = plt.subplots(figsize=(4.2, 3))\n",
    "    sns.regplot(data=df, x='Walc', y='G3', ax=ax, scatter_kws={'alpha': 0.5}, line_kws={'color': 'red'})\n",
    "    ax.set_xlabel(\"Weekend alcohol use (1 = none … 5 = heavy)\")\n",
    "    ax.set_ylabel(\"Final grade (G3)\")\n",
    "    ax.set_title(\"Grades by weekend alcohol use (regression)\")\n",
    "    save_figure(fig, Path(\"figures/Q1_G3_Walc_regression.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "871a1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_2(df, fout):\n",
    "    \"\"\"Q2 - absences vs grades.\"\"\"\n",
    "    fout.write(\"Q2: absences vs grades\\n\")\n",
    "    r, p = stats.pearsonr(df['absences'], df['G3'])\n",
    "    fout.write(f\" Pearson r = {r:.3f},  p = {p:.4g}\\n\")\n",
    "\n",
    "    low = df[df.absences <= 5]['G3']\n",
    "    high = df[df.absences >= 15]['G3']\n",
    "    t, p2 = stats.ttest_ind(low, high, equal_var=False)\n",
    "    fout.write(f\" Welch t-test (<=5 vs >=15 absences): \"\n",
    "               f\"t = {t:.2f}, p = {p2:.4g}\\n\\n\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4.2, 3))\n",
    "    sns.scatterplot(df, x='absences', y='G3', alpha=0.6, ax=ax)\n",
    "    sns.regplot(df, x='absences', y='G3',\n",
    "                scatter=False, color='red', ax=ax)\n",
    "    ax.set_xlim(-1)\n",
    "    ax.set_xlabel(\"Number of absences\")\n",
    "    ax.set_ylabel(\"Final grade (G3)\")\n",
    "    ax.set_title(\"absences vs grade\")\n",
    "    save_figure(fig, Path(\"figures/fig3_absences_scatter.png\"))\n",
    "    # \"\"\"Q2: Is there a difference in the average final grade (G3) between students who have romantic relationships and those who do not?\"\"\"\n",
    "    # df['Romantic'] = df['Romantic'].astype(int)\n",
    "    # with_romantic = df[df['Romantic'] == 1]['G3']\n",
    "    # without_romantic = df[df['Romantic'] == 0]['G3']\n",
    "    \n",
    "    # t_stat, p_value = stats.ttest_ind(with_romantic, without_romantic, equal_var=False)\n",
    "    \n",
    "    # fout.write(f\"\\nQ2: T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\\n\")\n",
    "    # if p_value < 0.05:\n",
    "    #     fout.write(\"Conclusion: There is a significant difference in G3 between students with and without romantic relationships.\\n\")\n",
    "    # else:\n",
    "    #     fout.write(\"Conclusion: No significant difference in G3 between groups.\\n\")\n",
    "    # Ensure figures directory exists\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5645e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_3(df, fout):\n",
    "    \"\"\"Q3: Is there a difference in the average final grade (G3) between students who study more than 2 hours per day and those who study less?\"\"\"\n",
    "    df['studytime'] = df['studytime'].astype(int)\n",
    "    more_than_2_hours = df[df['studytime'] > 2]['G3']\n",
    "    less_or_equal_2_hours = df[df['studytime'] <= 2]['G3']\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(more_than_2_hours, less_or_equal_2_hours, equal_var=False)\n",
    "    \n",
    "    fout.write(f\"\\nQ3: T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\\n\")\n",
    "    if p_value < 0.05:\n",
    "        fout.write(\"Conclusion: There is a significant difference in G3 between students studying more than 2 hours and those studying less.\\n\")\n",
    "    else:\n",
    "        fout.write(\"Conclusion: No significant difference in G3 between groups.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "6cb57567",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def question_4(df, fout):\n",
    "    \"\"\"Q4: Is there a difference in the average final grade (G3) between students who have a higher health status (health >= 3) and those who do not?\"\"\"\n",
    "    df['health'] = df['health'].astype(int)\n",
    "    higher_health = df[df['health'] >= 3]['G3']\n",
    "    lower_health = df[df['health'] < 3]['G3']\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(higher_health, lower_health, equal_var=False)\n",
    "    \n",
    "    fout.write(f\"\\nQ4: T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\\n\")\n",
    "    if p_value < 0.05:\n",
    "        fout.write(\"Conclusion: There is a significant difference in G3 between students with higher and lower health status.\\n\")\n",
    "    else:\n",
    "        fout.write(\"Conclusion: No significant difference in G3 between groups.\\n\")\n",
    "\n",
    "def question_5(df, fout):\n",
    "    # \"\"\"Q2: Is there a difference in the average final grade (G3) between students who have romantic relationships and those who do not?\"\"\"\n",
    "    # df['Romantic'] = df['Romantic'].astype(int)\n",
    "    # with_romantic = df[df['Romantic'] == 1]['G3']\n",
    "    # without_romantic = df[df['Romantic'] == 0]['G3']\n",
    "    \n",
    "    # t_stat, p_value = stats.ttest_ind(with_romantic, without_romantic, equal_var=False)\n",
    "    \n",
    "    # fout.write(f\"\\nQ2: T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\\n\")\n",
    "    # if p_value < 0.05:\n",
    "    #     fout.write(\"Conclusion: There is a significant difference in G3 between students with and without romantic relationships.\\n\")\n",
    "    # else:\n",
    "    #     fout.write(\"Conclusion: No significant difference in G3 between groups.\\n\")\n",
    "    # Ensure figures directory exists\n",
    "    \"\"\"Q5 - health rating vs grade.\"\"\"\n",
    "    fout.write(\"Q5: health rating vs grades\\n\")\n",
    "    rho, p = stats.spearmanr(df['health'], df['G3'])\n",
    "    fout.write(f\" Spearman ρ = {rho:.3f},  p = {p:.4g}\\n\")\n",
    "\n",
    "    model = smf.ols('G3 ~ C(health)', data=df).fit()\n",
    "    anova = sm.stats.anova_lm(model, typ=2)\n",
    "    fout.write(\" ANOVA health:\\n\")\n",
    "    fout.write(anova.to_string()); fout.write(\"\\n\\n\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    sns.violinplot(df, x='health', y='G3', palette='Greens', ax=ax)\n",
    "    ax.set_xlabel(\"Self-reported health (1=bad … 5=excellent)\")\n",
    "    ax.set_ylabel(\"Final grade (G3)\")\n",
    "    ax.set_title(\"Grades by health level\")\n",
    "    save_figure(fig, Path(\"figures/fig6_health.png\"))\n",
    "\n",
    "def question_6(df, fout):\n",
    "    \"\"\"Q6: Is there a difference in the average final grade (G3) between students who drink alcohol frequently (Dalc >= 3) and those who do not?\"\"\"\n",
    "    df['Dalc'] = df['Dalc'].astype(int)\n",
    "    frequent_drinkers = df[df['Dalc'] >= 3]['G3']\n",
    "    non_frequent_drinkers = df[df['Dalc'] < 3]['G3']\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(frequent_drinkers, non_frequent_drinkers, equal_var=False)\n",
    "    \n",
    "    fout.write(f\"\\nQ6: T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\\n\")\n",
    "    if p_value < 0.05:\n",
    "        fout.write(\"Conclusion: There is a significant difference in G3 between frequent and non-frequent drinkers.\\n\")\n",
    "    else:\n",
    "        fout.write(\"Conclusion: No significant difference in G3 between groups.\\n\")\n",
    "\n",
    "QUESTION_FUNCS = {\n",
    "    \"Q1\": question_1,\n",
    "    \"Q2\": question_2,\n",
    "    # \"Q3\": question_3,\n",
    "    # \"Q4\": question_4,\n",
    "    # \"Q5\": question_5,\n",
    "    # \"Q6\": question_6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "23f6cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_concat():\n",
    "    math_df = pd.read_csv('data/student-mat.csv')\n",
    "    por_df = pd.read_csv('data/student-por.csv')\n",
    "    # concat dataframes vertically\n",
    "    df = pd.concat([math_df, por_df], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a7efe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "Path(\"figures\").mkdir(exist_ok=True)\n",
    "\n",
    "df = load_and_concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c7f213f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Q1 ===\n",
      "[FIG] Saved → figures\\Q1_G3_Walc_boxplot.png\n",
      "[FIG] Saved → figures\\Q1_G3_Walc_regression.png\n",
      "\n",
      "=== Running Q2 ===\n",
      "[FIG] Saved → figures\\fig3_absences_scatter.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"results_summary.txt\", \"w\", encoding='utf-8') as fout:\n",
    "    for q in QUESTION_FUNCS:\n",
    "        print(f\"\\n=== Running {q} ===\")\n",
    "        QUESTION_FUNCS[q](df, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "cd5db4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FIG] Saved → figures\\correlation_matrix.png\n"
     ]
    }
   ],
   "source": [
    "# correlation matrix for Walc, G3, absences, Dalc, health, studytime. \n",
    "corr_df = df[['Walc', 'G3', 'absences', 'Dalc', 'health', 'studytime']]\n",
    "corr_matrix = corr_df.corr(method='pearson')   \n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax)\n",
    "ax.set_title(\"Correlation Matrix\")\n",
    "save_figure(fig, Path(\"figures/correlation_matrix.png\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1891aa8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[238], line 40\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 4. Pipeline: scale + logistic regression\u001b[39;00m\n\u001b[0;32m     36\u001b[0m pipe \u001b[38;5;241m=\u001b[39m make_pipeline(\n\u001b[0;32m     37\u001b[0m     StandardScaler(),\n\u001b[0;32m     38\u001b[0m     LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m )\n\u001b[1;32m---> 40\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# 5. Predictions & metrics\u001b[39;00m\n\u001b[0;32m     43\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:,\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sarel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sarel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    426\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 427\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sarel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sarel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1169\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;124;03m    Fit the model according to the given training data.\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;124;03m    The SAGA solver supports both float64 and float32 bit arrays.\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1169\u001b[0m     solver \u001b[38;5;241m=\u001b[39m \u001b[43m_check_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1173\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_ratio parameter is only used when penalty is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1174\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1175\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(penalty=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty)\n\u001b[0;32m   1176\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\sarel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:56\u001b[0m, in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_solver\u001b[39m(solver, penalty, dual):\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# TODO(1.4): Remove \"none\" option\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m penalty \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 56\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     57\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolver \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m supports only \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m penalties, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m penalty.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m             \u001b[38;5;241m%\u001b[39m (solver, penalty)\n\u001b[0;32m     59\u001b[0m         )\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dual:\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     62\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolver \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m supports only dual=False, got dual=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (solver, dual)\n\u001b[0;32m     63\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "# Cell: failure_prediction.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve,\n",
    "    confusion_matrix, accuracy_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# 2. Feature engineering\n",
    "binary_map = {\"yes\":1, \"no\":0}\n",
    "for col in [\"famsup\",\"schoolsup\",\"romantic\"]:\n",
    "    df[col] = df[col].map(binary_map)\n",
    "\n",
    "# Predictors and target\n",
    "PREDICTORS = [\"Walc\",\"Dalc\",\"absences\",\"studytime\",\"failures\",\n",
    "              \"famsup\",\"schoolsup\",\"health\",\"romantic\"]\n",
    "X = df[PREDICTORS]\n",
    "y = (df[\"G3\"] < 11).astype(int)  # 1=fail, 0=pass\n",
    "\n",
    "# 3. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. Pipeline: scale + logistic regression\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=10000, solver=\"lbfgs\")\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# 5. Predictions & metrics\n",
    "y_prob = pipe.predict_proba(X_test)[:,1]\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, digits=3)\n",
    "\n",
    "print(f\"AUC:      {auc:.3f}\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "# 6. Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve: Student Failure Prediction\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
